{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68191d55",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd145746",
   "metadata": {},
   "source": [
    "- 어텐션(attention)은 입력에 대한 벡터 변환을 인코더(encoder)에서 처리하고 모든 벡터를 디코더(decoder)로 보냄.\n",
    "이렇게 모든 벡터를 전달하는 것은 시간이 흐를수록 초기 정보를 잃어버리는 `기울기 소실`문제를 해결하기 위함임. \n",
    "그러나 모든 벡터가 전달됨으로써 행렬 크기가 매우 커지는 단점이 있는데, 이를 해결하기 위해 `소프트맥스 함수`를 사용하여\n",
    "가중합을 구하고, 그 값을 디코더에 전달함.\n",
    "\n",
    "- 가중합이 전달되면서, 정보를 많이 전달받은 디코더에게 부담이 가기 때문에, 디코더는 은닉 상태에 대하여\n",
    "중점적으로 `집중(attention)`해 보아야 할 벡터를 소프트맥스 함수로 점수매긴 후 각각을 은닉 상태 벡터들과 곱함.\n",
    "그리고 이 은닉 상태를 모두 더하여 하나의 값으로 만듦. 즉, 어텐션은 모든 벡터 중 꼭 살펴봐야 할 벡터에 집중하겠다는 의미임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57001ce",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "- 트랜스포머는 어텐션을 극대화하는 방법으로, 인코더와 디코더를 여러개 중첩시킨 구조임.\n",
    "이 때 각각의 인코더와 디코더를 `block`이라고 함(논문에서는 인코더와 디코더 블록을 6개씩 중첩한 구조 사용)\n",
    "\n",
    "- 하나의 인코더는 `self-attention`과 `전방향 신경망(feed-forward neural network)`으로 구성되어 있음.\n",
    "인코더에서는 단어를 벡터로 임베딩하며, 이를 셀프 어텐션과 전방향 신경망으로 전달함.\n",
    "이 때 셀프 어텐션은 문장에서 각 단어끼리 얼마나 관계하는지를 계산해서 반영함. 즉, 셀프 어텐션으로\n",
    "문장 안에서 단어 간 관계를 파악할 수 있음. 셀프 어텐션에서 파악된 단어간 관계는 전방향 신경망으로 전달됨\n",
    "\n",
    "- 디코더는 층을 총 3개 가지는데, 인코더에서 넘어온 벡터가 처음 만나는 것이 self-attention 층임.(인코더와 동일)\n",
    "셀프 어텐션 층을 지나면 인코더-디코더 어텐션 층이 있음. 이 층에서는 인코더가 처리한 정보를 받아 어텐션 메커니즘을 수행하고,\n",
    "마지막으로 전방향 신경망으로 데이터가 전달됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a8856",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "- 어텐션 메커니즘을 이용하기 위해서는 가장 먼저 `어텐션 스코어`를 구해야 함\n",
    "- 어텐션 스코어란, 현 디코더의 시점 i에서 단어를 예측하기 위해, 인코더의 모든 은닉상태 값($h_j$)이\n",
    "디코더의 현 시점 은닉 상태($s_i$)와 얼마나 유사한지(관련이 있는지)를 판단하는 값임. 따라서,\n",
    "어텐션 스코어는 앞 수식처럼 인코더의 모든 은닉 상태 값($h_j$)과 디코더에서 이전 시점 은닉상태($s_{i-1}$)\n",
    "값을 이용하여 구할 수 있음\n",
    "- 어텐션 스코어가 계산되면, 이 값을 소프트맥스 함수에 적용하여 확률로 변환하고,\n",
    "이렇게 계산된 0 ~ 1 사이의 값들이 특정 시점(timestep)에 대한 가중치, 즉 시간의 가중치가 됨.\n",
    "- 시간의 가중치($a_{ij}$)와 은닉 상태($h_j$)의 가중합을 계산하면 하나의 벡터가 계산되는데, 이것이 컨텍스트 벡터(context vector)임.\n",
    "- 마지막으로 디코더의 은닉 상태를 구하는데, 이를 위해 컨텍스트 벡터와 디코더 이전 시점의 은닉 상태와 출력이 필요함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3426b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18a0de9b",
   "metadata": {},
   "source": [
    "## Seq2seq\n",
    "- `seq2seq(sequence to seqeunce)`는 입력 시퀀스에 대한 출력 시퀀스를 만들기 위한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59a314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import unicode_literals, print_function, divison\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87eee7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang :\n",
    "    def __init__(self) :\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0 : 'SOS' , 1 : 'EOS'}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence) :\n",
    "        for word in sentence.split(' ') :\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word) :\n",
    "        if word not in self.word2index :\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else :\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86010d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(df, lang) :\n",
    "    sent = df[lang].str.lower()\n",
    "    sent = sent.str.replace('[^A-Za-z\\s]+', ' ')\n",
    "    sent = sent.str.normalize('NFD') # 유니코드 정규화\n",
    "    sent = sent.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return sent\n",
    "\n",
    "def read_sentence(df, lang1, lang2) :\n",
    "    sent1 = normalize_string(df, lang1)\n",
    "    sent2 = normalize_string(df, lang2)\n",
    "    return sent1, sent2\n",
    "\n",
    "def read_file(loc, lang1, lang2) :\n",
    "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2, 'etc'])\n",
    "    return df\n",
    "\n",
    "def process_data(lang1, lang2) :\n",
    "    df = read_file(f'./{lang2}-{lang1}/{lang2}.txt', lang1, lang2)\n",
    "    sent1, sent2 = read_sentence(df, lang1, lang2)\n",
    "    \n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    pairs = []\n",
    "    \n",
    "    for i in range(len(df)) :\n",
    "        if len(sent1[i].split(' ')) < MAX_LENGTH and len(sent2[i].split(' ')) < MAX_LENGTH : \n",
    "            full = [sent1[i], sent2[i]]\n",
    "            input_lang.addSentence(sent1[i])\n",
    "            output_lang.addSentence(sent2[i])\n",
    "            pairs.append(full)\n",
    "            \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f44e5f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서로 변환\n",
    "def indexesFromSentence(lang, sentence)  :\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence) :\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(input_lang, output_lang, pair) :\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3e8dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "    def __init__(self, input_dim, hidden_dim, embed_dim, num_layers) :\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim # 인코더 입력층\n",
    "        self.embed_dim = embed_dim # 인코더 임베딩 \n",
    "        self.hidden_dim = hidden_dim # 인코더 은닉층\n",
    "        self.num_layers = num_layers # 인코더 GRU 계층수\n",
    "        self.embedding = nn.Embedding(input_dim, self.embed_dim) # 임베딩 계층 초기화\n",
    "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "        \n",
    "    def forward(self, src) :\n",
    "        embed = self.embedding(src).view(1, 1, -1)\n",
    "        outputs, hidden = self.gru(embed)\n",
    "        return outputs, hidden\n",
    "\n",
    "    # 임베딩 계층에서는 출력하기 위해 딕셔너리 조회 테이블을 만들며, GRU 계층은 다음 단어 예측을 위한 확률을 계산함\n",
    "    # 선형 계층에서는 계산된 확률값 중 최적값(최종 출력 단어) 선택을 위해 소프트맥스 활성화 함수를 사용\n",
    "    \n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, output_dim, hidden_dim, embed_dim, num_layers) :\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, self.embed_dim)\n",
    "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden) :\n",
    "        input = input.view(1, -1)\n",
    "        embed = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embed, hidden)\n",
    "        prediction = self.softmax(self.out(output[0]))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d09694d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module) :\n",
    "    def __init__(self, encoder, decoder, device, max_length=MAX_LENGTH) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5) :\n",
    "        input_length = input_lang.size(0)\n",
    "        batch_size = output_lang.shape[1]\n",
    "        target_length = output_lang.shape[0]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "        \n",
    "        for i in range(input_length) :\n",
    "            encoder_output, encoder_hidden = self.encoder(input_lang[i]) # 문장 모든 단어 인코딩\n",
    "        decoder_hidden = encoder_hidden.to(device) # 인코더 은닉층을 디코더 은닉층으로 사용\n",
    "        decoder_input = torch.tensor([SOS_token], device=device) # 첫 예측단어 앞에 토큰(SOS) 추가\n",
    "        \n",
    "        for t in range(target_length) : # 현 단어에서 출력 단어 예측\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            input = (output_lang[t] if teacher_force else topi)\n",
    "            if (teacher_force == False and input.item() == EOS_token) :\n",
    "                break\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67dfe974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차계산함수 정의\n",
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def Model(model, input_tensor, target_tensor, model_optimizer, criterion) :\n",
    "    model_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "    \n",
    "    for ot in range(num_iter) :\n",
    "        loss += criterion(output[ot], target_tensor[ot])\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4237557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련함수 정의\n",
    "def trainModel(model, input_lang, output_lang, pairs, num_iter=20000) :\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss_iter = 0\n",
    "    \n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs)) for i in range(num_iter)]\n",
    "    \n",
    "    for iter in range(1, num_iter+1) :\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
    "        total_loss_iter += loss\n",
    "        \n",
    "        if iter % 5000 == 0 :\n",
    "            average_loss = total_loss_iter / 5000\n",
    "            total_loss_iter = 0\n",
    "            print(f'{iter} | {average_loss:.4f}')\n",
    "    \n",
    "    torch.save(model.state_dict(), './custom_model.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8087b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH) :\n",
    "    with torch.no_grad() :\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
    "        decoded_words = []\n",
    "        output = model(input_tensor, output_tensor)\n",
    "        \n",
    "        for ot in range(output.size(0)) :\n",
    "            topv, topi = output[ot].topk(1)\n",
    "            \n",
    "            if topi[0].item() == EOS_token :\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else :\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "        print(decoded_words)\n",
    "        return decoded_words\n",
    "    \n",
    "    \n",
    "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10) :\n",
    "    for i in range(n) :\n",
    "        pair = random.choice(pairs)\n",
    "        print(f'input : {pair[0]}')\n",
    "        print(f'output : {pair[1]}') \n",
    "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
    "        output_sentences = ' '.join(output_words)\n",
    "        print(f'predicted : {output_sentences}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "870ff63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\yeseul\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e483510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence : ['how many spoonfuls of sugar do you usually put in your tea ', 'combien de cuill res de sucre mettez vous g n ralement dans votre th  ']\n",
      "Input : 14732 Output : 20929\n"
     ]
    }
   ],
   "source": [
    "randomize = random.choice(pairs)\n",
    "print('random sentence :',randomize)\n",
    "\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "print(f'Input : {input_size} Output : {output_size}')\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 75000\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3824c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(14732, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(20929, 256)\n",
      "  (gru): GRU(256, 512)\n",
      "  (out): Linear(in_features=512, out_features=20929, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Seq2seq(encoder, decoder, device).to(device)\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "\n",
    "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 문장 평가\n",
    "evaluateRandomly(model, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6b154",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b276ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 적용 디코더\n",
    "class AttnDecoderRNN(nn.Module) :\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH) :\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "ㅣ\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs) :\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0], 1))), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 디코더 모델 학습\n",
    "def train_iters(encoder, decoder, n_iters, print_every=1000, plot_every=100, lr=0.01) :\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1) :\n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % 5000 == 0 :\n",
    "            print_loss_avg = print_loss_total // 5000\n",
    "            print_loss_total = 0\n",
    "            print(f'{iter} | {print_loss_avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496de052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 디코더 모델 훈련\n",
    "import time\n",
    "\n",
    "embed_size =256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "\n",
    "encoder1= Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
    "print(encoder1)\n",
    "print(attn_decoder1)\n",
    "\n",
    "attn_model = train_iters(encoder1, attn_decoder1, 75000, print_every=5000,\n",
    "                        plot_every=100, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5763302",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(attn_model, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48779ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ae160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834c172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ff283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05309862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeseul",
   "language": "python",
   "name": "yeseul"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
